{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINMA Python Lab 08 - Solutions\n",
    "\n",
    "This notebook contains complete solutions for all exercises in Lab 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Portfolio Value Calculation (NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Portfolio Value Calculation\n",
    "\n",
    "# Data\n",
    "symbols = np.array(['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA'])\n",
    "shares = np.array([150, 75, 100, 60, 40])\n",
    "prices = np.array([163.75, 155.30, 406.20, 200.45, 276.30])\n",
    "\n",
    "# 1. Calculate value of each position\n",
    "position_values = shares * prices\n",
    "print(\"Position Values:\")\n",
    "for symbol, value in zip(symbols, position_values):\n",
    "    print(f\"{symbol}: ${value:,.2f}\")\n",
    "\n",
    "# 2. Calculate total portfolio value\n",
    "total_value = np.sum(position_values)\n",
    "print(f\"\\nTotal Portfolio Value: ${total_value:,.2f}\")\n",
    "\n",
    "# 3. Calculate percentage allocation\n",
    "percentages = (position_values / total_value) * 100\n",
    "print(\"\\nPercentage Allocation:\")\n",
    "for symbol, pct in zip(symbols, percentages):\n",
    "    print(f\"{symbol}: {pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Return Statistics (NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Return Statistics\n",
    "\n",
    "# Daily returns (in percentage)\n",
    "returns = np.array([1.2, -0.5, 0.8, 1.5, -0.3, 0.9, 1.1, -0.7, 1.3, 0.6])\n",
    "\n",
    "# 1. Average daily return\n",
    "avg_daily_return = np.mean(returns)\n",
    "print(f\"Average Daily Return: {avg_daily_return:.4f}%\")\n",
    "\n",
    "# 2. Volatility (standard deviation)\n",
    "daily_volatility = np.std(returns, ddof=1)  # ddof=1 for sample std\n",
    "print(f\"Daily Volatility: {daily_volatility:.4f}%\")\n",
    "\n",
    "# 3. Annualized return (252 trading days)\n",
    "annualized_return = avg_daily_return * 252\n",
    "print(f\"Annualized Return: {annualized_return:.2f}%\")\n",
    "\n",
    "# 4. Annualized volatility\n",
    "annualized_volatility = daily_volatility * np.sqrt(252)\n",
    "print(f\"Annualized Volatility: {annualized_volatility:.2f}%\")\n",
    "\n",
    "# 5. Sharpe ratio (risk-free rate = 2%)\n",
    "risk_free_rate = 2.0\n",
    "sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Price Matrix Analysis (NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Price Matrix Analysis\n",
    "\n",
    "# Read first 10 days of data\n",
    "df = pd.read_csv('sample_data_lab8/stock_prices_timeseries.csv')\n",
    "price_matrix = df.iloc[:10, 1:].values  # First 10 days, all stocks except Date\n",
    "\n",
    "symbols = df.columns[1:].tolist()\n",
    "\n",
    "print(\"Price Matrix Shape:\", price_matrix.shape)\n",
    "print(\"\\nPrice Matrix:\")\n",
    "print(price_matrix)\n",
    "\n",
    "# 1. Average price for each stock\n",
    "avg_prices = np.mean(price_matrix, axis=0)\n",
    "print(\"\\n1. Average Price by Stock:\")\n",
    "for symbol, avg in zip(symbols, avg_prices):\n",
    "    print(f\"{symbol}: ${avg:.2f}\")\n",
    "\n",
    "# 2. Highest price for each stock\n",
    "max_prices = np.max(price_matrix, axis=0)\n",
    "print(\"\\n2. Highest Price by Stock:\")\n",
    "for symbol, max_p in zip(symbols, max_prices):\n",
    "    print(f\"{symbol}: ${max_p:.2f}\")\n",
    "\n",
    "# 3. Lowest price for each stock\n",
    "min_prices = np.min(price_matrix, axis=0)\n",
    "print(\"\\n3. Lowest Price by Stock:\")\n",
    "for symbol, min_p in zip(symbols, min_prices):\n",
    "    print(f\"{symbol}: ${min_p:.2f}\")\n",
    "\n",
    "# 4. Stock with highest average price\n",
    "highest_avg_idx = np.argmax(avg_prices)\n",
    "print(f\"\\n4. Stock with Highest Average: {symbols[highest_avg_idx]} (${avg_prices[highest_avg_idx]:.2f})\")\n",
    "\n",
    "# 5. Day with highest average price\n",
    "avg_by_day = np.mean(price_matrix, axis=1)\n",
    "highest_day_idx = np.argmax(avg_by_day)\n",
    "print(f\"\\n5. Day with Highest Average: Day {highest_day_idx + 1} (${avg_by_day[highest_day_idx]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: DataFrame Creation and Analysis (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: DataFrame Creation and Analysis\n",
    "\n",
    "# Read company info\n",
    "companies = pd.read_csv('sample_data_lab8/company_info.csv')\n",
    "\n",
    "# 1. Display first 5 rows\n",
    "print(\"1. First 5 rows:\")\n",
    "print(companies.head())\n",
    "\n",
    "# 2. Show summary statistics\n",
    "print(\"\\n2. Summary Statistics:\")\n",
    "print(companies.describe())\n",
    "\n",
    "# 3. Company with highest market cap\n",
    "highest_mc = companies.loc[companies['market_cap'].idxmax()]\n",
    "print(f\"\\n3. Highest Market Cap: {highest_mc['company']} (${highest_mc['market_cap']:.1f}B)\")\n",
    "\n",
    "# 4. Company with highest P/E ratio\n",
    "highest_pe = companies.loc[companies['pe_ratio'].idxmax()]\n",
    "print(f\"\\n4. Highest P/E Ratio: {highest_pe['company']} ({highest_pe['pe_ratio']:.1f})\")\n",
    "\n",
    "# 5. Average dividend yield by sector\n",
    "print(\"\\n5. Average Dividend Yield by Sector:\")\n",
    "avg_dividend = companies.groupby('sector')['dividend_yield'].mean()\n",
    "print(avg_dividend)\n",
    "\n",
    "# 6. List all Technology sector companies\n",
    "print(\"\\n6. Technology Sector Companies:\")\n",
    "tech_companies = companies[companies['sector'] == 'Technology']\n",
    "print(tech_companies[['symbol', 'company', 'industry']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Transaction Analysis (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Transaction Analysis\n",
    "\n",
    "# Read transactions\n",
    "transactions = pd.read_csv('sample_data_lab8/transactions.csv')\n",
    "\n",
    "# 1. Calculate total shares bought and sold\n",
    "print(\"1. Shares Bought and Sold by Symbol:\")\n",
    "summary = transactions.groupby(['symbol', 'action'])['shares'].sum().unstack(fill_value=0)\n",
    "print(summary)\n",
    "\n",
    "# 2. Calculate total commission paid\n",
    "total_commission = transactions['commission'].sum()\n",
    "print(f\"\\n2. Total Commission Paid: ${total_commission:.2f}\")\n",
    "\n",
    "# 3. Calculate average buy and sell prices\n",
    "print(\"\\n3. Average Prices:\")\n",
    "avg_prices = transactions.groupby(['symbol', 'action']).agg({\n",
    "    'price': 'mean',\n",
    "    'shares': 'sum'\n",
    "})\n",
    "print(avg_prices)\n",
    "\n",
    "# 4. Determine current holdings\n",
    "print(\"\\n4. Current Holdings:\")\n",
    "buys = transactions[transactions['action'] == 'BUY'].groupby('symbol')['shares'].sum()\n",
    "sells = transactions[transactions['action'] == 'SELL'].groupby('symbol')['shares'].sum()\n",
    "holdings = buys.subtract(sells, fill_value=0)\n",
    "print(holdings)\n",
    "\n",
    "# 5. Export summary to CSV\n",
    "# Calculate metrics for export\n",
    "avg_buy_prices = transactions[transactions['action'] == 'BUY'].groupby('symbol')['price'].mean()\n",
    "commission_by_symbol = transactions.groupby('symbol')['commission'].sum()\n",
    "\n",
    "export_df = pd.DataFrame({\n",
    "    'symbol': holdings.index,\n",
    "    'shares_held': holdings.values,\n",
    "    'avg_buy_price': avg_buy_prices[holdings.index].values,\n",
    "    'total_commission': commission_by_symbol[holdings.index].values\n",
    "})\n",
    "\n",
    "export_df.to_csv('output/holdings_summary.csv', index=False)\n",
    "print(\"\\n5. Summary exported to output/holdings_summary.csv\")\n",
    "print(export_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 6: Time Series Returns (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Time Series Returns\n",
    "\n",
    "# 1. Read data with Date as index\n",
    "prices_df = pd.read_csv('sample_data_lab8/stock_prices_timeseries.csv')\n",
    "prices_df['Date'] = pd.to_datetime(prices_df['Date'])\n",
    "prices_df.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Price Data:\")\n",
    "print(prices_df.head())\n",
    "\n",
    "# 2. Calculate daily returns\n",
    "returns = prices_df.pct_change() * 100  # Convert to percentage\n",
    "print(\"\\nDaily Returns (%):\")\n",
    "print(returns.head())\n",
    "\n",
    "# 3. Calculate cumulative returns\n",
    "cumulative_returns = (1 + prices_df.pct_change()).cumprod() - 1\n",
    "total_returns = cumulative_returns.iloc[-1] * 100\n",
    "\n",
    "print(\"\\nTotal Returns (%):\")\n",
    "print(total_returns)\n",
    "\n",
    "# 4. Find stocks with extreme characteristics\n",
    "print(\"\\n4. Stock Characteristics:\")\n",
    "print(f\"Highest Total Return: {total_returns.idxmax()} ({total_returns.max():.2f}%)\")\n",
    "print(f\"Lowest Total Return: {total_returns.idxmin()} ({total_returns.min():.2f}%)\")\n",
    "\n",
    "volatilities = returns.std()\n",
    "print(f\"Highest Volatility: {volatilities.idxmax()} ({volatilities.max():.2f}%)\")\n",
    "print(f\"Lowest Volatility: {volatilities.idxmin()} ({volatilities.min():.2f}%)\")\n",
    "\n",
    "# 5. Export daily returns\n",
    "returns.to_csv('output/daily_returns.csv')\n",
    "print(\"\\n5. Daily returns exported to output/daily_returns.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 7: Moving Averages (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7: Moving Averages\n",
    "\n",
    "# Read data\n",
    "prices_df = pd.read_csv('sample_data_lab8/stock_prices_timeseries.csv')\n",
    "prices_df['Date'] = pd.to_datetime(prices_df['Date'])\n",
    "prices_df.set_index('Date', inplace=True)\n",
    "\n",
    "# 1. Calculate 5-day and 10-day moving averages for AAPL\n",
    "prices_df['AAPL_MA5'] = prices_df['AAPL'].rolling(window=5).mean()\n",
    "prices_df['AAPL_MA10'] = prices_df['AAPL'].rolling(window=10).mean()\n",
    "\n",
    "print(\"AAPL with Moving Averages:\")\n",
    "print(prices_df[['AAPL', 'AAPL_MA5', 'AAPL_MA10']].head(15))\n",
    "\n",
    "# 2 & 3. Identify crossover signals\n",
    "# Buy signal: price crosses above MA5\n",
    "# Sell signal: price crosses below MA5\n",
    "\n",
    "prices_df['Signal'] = ''\n",
    "for i in range(1, len(prices_df)):\n",
    "    if pd.notna(prices_df['AAPL_MA5'].iloc[i]):\n",
    "        # Check if price crosses above MA (buy signal)\n",
    "        if (prices_df['AAPL'].iloc[i] > prices_df['AAPL_MA5'].iloc[i] and \n",
    "            prices_df['AAPL'].iloc[i-1] <= prices_df['AAPL_MA5'].iloc[i-1]):\n",
    "            prices_df.loc[prices_df.index[i], 'Signal'] = 'BUY'\n",
    "        # Check if price crosses below MA (sell signal)\n",
    "        elif (prices_df['AAPL'].iloc[i] < prices_df['AAPL_MA5'].iloc[i] and \n",
    "              prices_df['AAPL'].iloc[i-1] >= prices_df['AAPL_MA5'].iloc[i-1]):\n",
    "            prices_df.loc[prices_df.index[i], 'Signal'] = 'SELL'\n",
    "\n",
    "# 4. Count signals\n",
    "buy_signals = (prices_df['Signal'] == 'BUY').sum()\n",
    "sell_signals = (prices_df['Signal'] == 'SELL').sum()\n",
    "\n",
    "print(f\"\\nBuy Signals: {buy_signals}\")\n",
    "print(f\"Sell Signals: {sell_signals}\")\n",
    "\n",
    "# Show days with signals\n",
    "signals_df = prices_df[prices_df['Signal'] != '']\n",
    "print(\"\\nDays with Signals:\")\n",
    "print(signals_df[['AAPL', 'AAPL_MA5', 'Signal']])\n",
    "\n",
    "# 5. Create final DataFrame\n",
    "result_df = prices_df[['AAPL', 'AAPL_MA5', 'AAPL_MA10', 'Signal']].copy()\n",
    "result_df.columns = ['Price', 'MA5', 'MA10', 'Signal']\n",
    "result_df.to_csv('output/aapl_moving_averages.csv')\n",
    "print(\"\\nData exported to output/aapl_moving_averages.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 8: Portfolio Performance Report (Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Portfolio Performance Report\n",
    "\n",
    "# 1. Read transactions to determine holdings\n",
    "transactions = pd.read_csv('sample_data_lab8/transactions.csv')\n",
    "\n",
    "# Calculate current holdings and cost basis\n",
    "holdings_data = []\n",
    "for symbol in transactions['symbol'].unique():\n",
    "    symbol_trans = transactions[transactions['symbol'] == symbol]\n",
    "    \n",
    "    buys = symbol_trans[symbol_trans['action'] == 'BUY']\n",
    "    sells = symbol_trans[symbol_trans['action'] == 'SELL']\n",
    "    \n",
    "    shares_bought = buys['shares'].sum()\n",
    "    shares_sold = sells['shares'].sum()\n",
    "    shares_held = shares_bought - shares_sold\n",
    "    \n",
    "    # Calculate weighted average buy price\n",
    "    total_cost = (buys['shares'] * buys['price']).sum() + buys['commission'].sum()\n",
    "    avg_buy_price = total_cost / shares_bought if shares_bought > 0 else 0\n",
    "    \n",
    "    holdings_data.append({\n",
    "        'symbol': symbol,\n",
    "        'shares': shares_held,\n",
    "        'avg_buy_price': avg_buy_price,\n",
    "        'cost_basis': shares_held * avg_buy_price\n",
    "    })\n",
    "\n",
    "holdings_df = pd.DataFrame(holdings_data)\n",
    "holdings_df = holdings_df[holdings_df['shares'] > 0]  # Only keep positive holdings\n",
    "\n",
    "# 2. Get latest prices\n",
    "prices_df = pd.read_csv('sample_data_lab8/stock_prices_timeseries.csv')\n",
    "latest_prices = prices_df.iloc[-1][['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']]\n",
    "latest_prices_dict = latest_prices.to_dict()\n",
    "\n",
    "# 3. Merge with company info\n",
    "companies = pd.read_csv('sample_data_lab8/company_info.csv')\n",
    "holdings_df = pd.merge(holdings_df, companies[['symbol', 'company', 'sector']], on='symbol')\n",
    "\n",
    "# 4. Calculate metrics\n",
    "holdings_df['current_price'] = holdings_df['symbol'].map(latest_prices_dict)\n",
    "holdings_df['current_value'] = holdings_df['shares'] * holdings_df['current_price']\n",
    "holdings_df['gain_loss'] = holdings_df['current_value'] - holdings_df['cost_basis']\n",
    "holdings_df['return_pct'] = (holdings_df['gain_loss'] / holdings_df['cost_basis']) * 100\n",
    "\n",
    "# 5. Portfolio-level metrics\n",
    "total_value = holdings_df['current_value'].sum()\n",
    "total_cost = holdings_df['cost_basis'].sum()\n",
    "total_gain_loss = holdings_df['gain_loss'].sum()\n",
    "overall_return = (total_gain_loss / total_cost) * 100\n",
    "\n",
    "# Calculate allocation by sector\n",
    "sector_allocation = holdings_df.groupby('sector')['current_value'].sum() / total_value * 100\n",
    "\n",
    "# Display report\n",
    "print(\"PORTFOLIO PERFORMANCE REPORT\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\\nHoldings:\")\n",
    "print(holdings_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PORTFOLIO SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"Total Current Value: ${total_value:,.2f}\")\n",
    "print(f\"Total Cost Basis: ${total_cost:,.2f}\")\n",
    "print(f\"Total Gain/Loss: ${total_gain_loss:,.2f}\")\n",
    "print(f\"Overall Return: {overall_return:+.2f}%\")\n",
    "\n",
    "print(\"\\nSector Allocation:\")\n",
    "for sector, pct in sector_allocation.items():\n",
    "    print(f\"  {sector}: {pct:.2f}%\")\n",
    "\n",
    "# 6. Export to CSV\n",
    "holdings_df.to_csv('output/portfolio_performance.csv', index=False)\n",
    "print(\"\\nFull report exported to output/portfolio_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 9: Correlation Analysis (Pandas + NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9: Correlation Analysis\n",
    "\n",
    "# 1. Read data\n",
    "prices_df = pd.read_csv('sample_data_lab8/stock_prices_timeseries.csv')\n",
    "prices_df['Date'] = pd.to_datetime(prices_df['Date'])\n",
    "prices_df.set_index('Date', inplace=True)\n",
    "\n",
    "# 2. Calculate daily returns\n",
    "returns = prices_df.pct_change().dropna()\n",
    "\n",
    "print(\"Daily Returns:\")\n",
    "print(returns.head())\n",
    "\n",
    "# 3. Create correlation matrix\n",
    "correlation_matrix = returns.corr()\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# 4. Find pairs with highest and lowest correlation\n",
    "# Create mask to exclude diagonal and duplicates\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "corr_values = correlation_matrix.mask(mask)\n",
    "\n",
    "# Find highest correlation (excluding 1.0 on diagonal)\n",
    "max_corr = corr_values.max().max()\n",
    "max_pair = corr_values.stack().idxmax()\n",
    "print(f\"\\nHighest Correlation: {max_pair[0]} - {max_pair[1]}: {max_corr:.4f}\")\n",
    "\n",
    "# Find lowest correlation\n",
    "min_corr = corr_values.min().min()\n",
    "min_pair = corr_values.stack().idxmin()\n",
    "print(f\"Lowest Correlation: {min_pair[0]} - {min_pair[1]}: {min_corr:.4f}\")\n",
    "\n",
    "# 5. Calculate portfolio variance for equal-weighted portfolio\n",
    "n_stocks = len(returns.columns)\n",
    "weights = np.array([1/n_stocks] * n_stocks)  # Equal weights\n",
    "\n",
    "# Covariance matrix\n",
    "cov_matrix = returns.cov()\n",
    "\n",
    "# Portfolio variance = w^T * Cov * w\n",
    "portfolio_variance = np.dot(weights, np.dot(cov_matrix, weights))\n",
    "portfolio_std = np.sqrt(portfolio_variance)\n",
    "\n",
    "# Annualize (252 trading days)\n",
    "annualized_volatility = portfolio_std * np.sqrt(252) * 100\n",
    "\n",
    "print(f\"\\nEqual-Weighted Portfolio:\")\n",
    "print(f\"Daily Volatility: {portfolio_std*100:.4f}%\")\n",
    "print(f\"Annualized Volatility: {annualized_volatility:.2f}%\")\n",
    "\n",
    "# Export correlation matrix\n",
    "correlation_matrix.to_csv('output/correlation_matrix.csv')\n",
    "print(\"\\nCorrelation matrix exported to output/correlation_matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 10: Risk-Adjusted Returns (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10: Risk-Adjusted Returns\n",
    "\n",
    "# Read data\n",
    "prices_df = pd.read_csv('sample_data_lab8/stock_prices_timeseries.csv')\n",
    "prices_df['Date'] = pd.to_datetime(prices_df['Date'])\n",
    "prices_df.set_index('Date', inplace=True)\n",
    "\n",
    "# 1. Calculate daily and annualized returns\n",
    "returns = prices_df.pct_change().dropna()\n",
    "mean_daily_returns = returns.mean()\n",
    "annualized_returns = mean_daily_returns * 252 * 100  # Convert to percentage\n",
    "\n",
    "# 2. Calculate volatility\n",
    "daily_volatility = returns.std()\n",
    "annualized_volatility = daily_volatility * np.sqrt(252) * 100\n",
    "\n",
    "# 3. Calculate Sharpe Ratio\n",
    "risk_free_rate = 2.0  # 2% annual\n",
    "sharpe_ratios = (annualized_returns - risk_free_rate) / annualized_volatility\n",
    "\n",
    "# 4. Calculate Maximum Drawdown\n",
    "def calculate_max_drawdown(prices):\n",
    "    \"\"\"Calculate maximum drawdown for a price series\"\"\"\n",
    "    cumulative_max = prices.cummax()\n",
    "    drawdown = (prices - cumulative_max) / cumulative_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    return max_drawdown * 100  # Convert to percentage\n",
    "\n",
    "max_drawdowns = prices_df.apply(calculate_max_drawdown)\n",
    "\n",
    "# 5. Calculate total returns\n",
    "total_returns = ((prices_df.iloc[-1] / prices_df.iloc[0]) - 1) * 100\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Symbol': prices_df.columns,\n",
    "    'Total_Return_%': total_returns.values,\n",
    "    'Annualized_Return_%': annualized_returns.values,\n",
    "    'Annualized_Volatility_%': annualized_volatility.values,\n",
    "    'Sharpe_Ratio': sharpe_ratios.values,\n",
    "    'Max_Drawdown_%': max_drawdowns.values\n",
    "})\n",
    "\n",
    "# Rankings\n",
    "print(\"RISK-ADJUSTED RETURNS ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\\nComplete Metrics:\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"RANKINGS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Rank by total return\n",
    "print(\"\\nBy Total Return:\")\n",
    "print(summary.sort_values('Total_Return_%', ascending=False)[['Symbol', 'Total_Return_%']].to_string(index=False))\n",
    "\n",
    "# Rank by Sharpe ratio\n",
    "print(\"\\nBy Sharpe Ratio (Risk-Adjusted):\")\n",
    "print(summary.sort_values('Sharpe_Ratio', ascending=False)[['Symbol', 'Sharpe_Ratio']].to_string(index=False))\n",
    "\n",
    "# Rank by volatility (risk)\n",
    "print(\"\\nBy Risk (Volatility - Lower is Better):\")\n",
    "print(summary.sort_values('Annualized_Volatility_%')[['Symbol', 'Annualized_Volatility_%']].to_string(index=False))\n",
    "\n",
    "# 6. Export analysis\n",
    "summary.to_csv('output/risk_adjusted_returns.csv', index=False)\n",
    "print(\"\\nAnalysis exported to output/risk_adjusted_returns.csv\")\n",
    "\n",
    "# Additional insights\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 100)\n",
    "best_return = summary.loc[summary['Total_Return_%'].idxmax()]\n",
    "best_sharpe = summary.loc[summary['Sharpe_Ratio'].idxmax()]\n",
    "lowest_risk = summary.loc[summary['Annualized_Volatility_%'].idxmin()]\n",
    "\n",
    "print(f\"\\nBest Performer (Return): {best_return['Symbol']} ({best_return['Total_Return_%']:.2f}%)\")\n",
    "print(f\"Best Risk-Adjusted (Sharpe): {best_sharpe['Symbol']} ({best_sharpe['Sharpe_Ratio']:.4f})\")\n",
    "print(f\"Lowest Risk: {lowest_risk['Symbol']} ({lowest_risk['Annualized_Volatility_%']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "All exercises completed! Key takeaways:\n",
    "\n",
    "1. **NumPy** excels at fast numerical operations on arrays\n",
    "2. **Pandas** makes data manipulation and analysis intuitive\n",
    "3. **Time series** analysis is crucial for financial data\n",
    "4. **Risk metrics** (volatility, Sharpe ratio, drawdown) are essential\n",
    "5. **Correlation** helps understand portfolio diversification\n",
    "6. **Proper data structures** lead to cleaner code\n",
    "\n",
    "### Files Created:\n",
    "- `output/holdings_summary.csv`\n",
    "- `output/daily_returns.csv`\n",
    "- `output/aapl_moving_averages.csv`\n",
    "- `output/portfolio_performance.csv`\n",
    "- `output/correlation_matrix.csv`\n",
    "- `output/risk_adjusted_returns.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
